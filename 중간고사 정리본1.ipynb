{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4wOmblqcXZN"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0affXfMcXZR"
      },
      "source": [
        "# The mathematical building blocks of neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqYEyDiAcXZS"
      },
      "source": [
        "## A first look at a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt3RatlqcXZS"
      },
      "source": [
        "**Loading the MNIST dataset in Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8dbaZuJc98D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "wmCK92cMcXZT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRQykBYExswj",
        "outputId": "ce0a6aa1-0965-4d79-a3f5-9650f37c87b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLaG7PsPcXZU",
        "outputId": "e1cc6377-95a1-47a4-9951-3267feb53e08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape # 벡터 형태태"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZIkhPeJcXZV",
        "outputId": "6f0325ca-b6a8-4a90-ece8-73568f4b3531"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_labels) #데이터의 양양"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VlCdl3acXZV",
        "outputId": "4b1fb1ca-ec42-40cc-a2a1-03d13a9c9ffc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels # 데이터 보기기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzDrI6KwcXZW"
      },
      "outputs": [],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52b0cd-kcXZW"
      },
      "outputs": [],
      "source": [
        "len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzEvMdxccXZX"
      },
      "outputs": [],
      "source": [
        "test_labels"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#데이터의 최대값"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "max(train_images.reshape(-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f1Ogih5cXZX"
      },
      "source": [
        "**The network architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0fCwt5YjcXZX"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njAJT0WrcXZY"
      },
      "source": [
        "**The compilation step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M64BTsiGcXZY"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E2R82UDcXZZ"
      },
      "source": [
        "**#데이터 표준화**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SQJUtOJycXZZ"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIvhpEOHcXZa"
      },
      "source": [
        "**###fitting 배치와 epochs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NifbPtXfcXZb",
        "outputId": "45d10a30-3fc9-4966-d25a-c513a29f65b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 7s 3ms/step - loss: 0.2651 - accuracy: 0.9234\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1089 - accuracy: 0.9682\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9789\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0507 - accuracy: 0.9848\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9891\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f34fe832d90>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQLBB3uKcXZb"
      },
      "source": [
        "**Using the model to make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbFn0cTdcXZc",
        "outputId": "e8428401-f039-47dc-fe2d-32f63d786eed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([4.2003540e-10, 2.1805117e-10, 4.4659970e-07, 2.4922067e-06,\n",
              "       3.4075468e-12, 5.8632443e-10, 8.0622758e-14, 9.9999702e-01,\n",
              "       1.2868580e-08, 1.2508009e-08], dtype=float32)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_digits = test_images[0:10]\n",
        "predictions = model.predict(test_digits)\n",
        "predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5DwkTzsezZE"
      },
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ai7qXwRcXZd",
        "outputId": "92f7ff4f-3bc7-40ae-f401-c20758b43dfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions[0].argmax() # 몇번째가 젤 큰 수냐냐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koG_YwxbcXZd",
        "outputId": "0030eac4-26c0-4230-8ef4-43a316cd97f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.999997"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions[0][7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ao23VWocXZe",
        "outputId": "3bacedee-58f3-4102-b94c-6b3fc5b303ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvTpF1a8cXZf"
      },
      "source": [
        "**Evaluating the model on new data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWaz8wzacXZf",
        "outputId": "4698bd55-f6d5-45dc-e096-c222b1c62b38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9701\n",
            "test_acc: 0.9700999855995178\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6hOp9JXcXZg"
      },
      "source": [
        "## vector 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7ohhdlUgs0X"
      },
      "outputs": [],
      "source": [
        "x.ndim #차원을 보여줌줌 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4h2pjTqcXZg"
      },
      "source": [
        "### Scalars (rank-0 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dtvEnY3cXZh",
        "outputId": "4ddacab8-d705-41b4-c026-711d96915638"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(12)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STaa9HSPcXZh",
        "outputId": "9be1ece8-30bc-428f-eff0-57d46e8bd96b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuwIvyPDcXZi"
      },
      "source": [
        "### Vectors (rank-1 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_1tPtGpcXZi"
      },
      "outputs": [],
      "source": [
        "x = np.array([12, 3, 6, 14, 7])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTcr7uNlcXZj"
      },
      "outputs": [],
      "source": [
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISPnR3dfcXZj"
      },
      "source": [
        "### Matrices (rank-2 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KoH4xTCcXZk"
      },
      "outputs": [],
      "source": [
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXjUECagcXZl"
      },
      "source": [
        "### Rank-3 and higher-rank tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33MeRoaDcXZl",
        "outputId": "84dafdab-194c-4f9c-cb87-1925e8880410"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([[[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]]])\n",
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHWaPh_zcXZm"
      },
      "source": [
        "### #변수 차원 확인인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "z695rRe_cXZm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmi2cmPRcXZn",
        "outputId": "e22b2c69-a095-43e1-d088-0ace2de9ace6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbfiVIWXcXZn",
        "outputId": "e093be17-9e78-4903-a06c-4974988a5aec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU4r_jwWcXZo",
        "outputId": "4f565f58-1e63-4982-cc4e-02b5be64abfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt4TtQldcXZo"
      },
      "source": [
        "**Displaying the fourth digit**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APcZjBChcXZo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "digit = train_images[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjwWk7Z5cXZp"
      },
      "outputs": [],
      "source": [
        "train_labels[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M78rxtkycXZp"
      },
      "source": [
        "### 데이터 쪼개기기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5_E2viKcXZq"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[10:100]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsyNmVdYcXZq"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[10:100, :, :]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmmOcEQjcXZr"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[10:100, 0:28, 0:28]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vsEWme5cXZr"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[:, 14:, 14:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QejYAVQgcXZs"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[:, 7:-7, 7:-7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bShVeV2QcXZs"
      },
      "source": [
        "### 배치를 일일이 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F66Tak60cXZt"
      },
      "outputs": [],
      "source": [
        "batch = train_images[:128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCfxpQ93cXZt"
      },
      "outputs": [],
      "source": [
        "batch = train_images[128:256]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w-EV-yvcXZu"
      },
      "outputs": [],
      "source": [
        "n = 3\n",
        "batch = train_images[128 * n:128 * (n + 1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HebiBP1cXZw"
      },
      "source": [
        "## The gears of neural networks: tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGu16HmKcXZx"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 코드로 형식 지정됨\n",
        "```\n",
        "\n",
        "### relu function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "lxfIPCKecXZx"
      },
      "outputs": [],
      "source": [
        "def naive_relu(x):\n",
        "    assert len(x.shape) == 2\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] = max(x[i, j], 0)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UNi8KxaQcXZy"
      },
      "outputs": [],
      "source": [
        "def naive_add(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert x.shape == y.shape\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[i, j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXFj0xllcXZy",
        "outputId": "42ff1958-349c-4d5e-99f5-d79f748e6a65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Took: 0.03 s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = x + y\n",
        "    z = np.maximum(z, 0.)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFbb4HsLcXZz",
        "outputId": "17ca69fe-da0f-4dfe-97a2-b0b45f437d6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Took: 1.87 s\n"
          ]
        }
      ],
      "source": [
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = naive_add(x, y)\n",
        "    z = naive_relu(z)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYK3ynKAo6l1",
        "outputId": "dd70dc5e-c5bc-4bd8-b920-5a077b1efc1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.66051828, 1.46085551, 1.35973242, ..., 0.98933304, 0.41299971,\n",
              "        1.22413736],\n",
              "       [1.23807262, 1.53697567, 1.61265136, ..., 1.5502652 , 0.73420732,\n",
              "        0.43474205],\n",
              "       [0.29816374, 0.67020901, 1.09052233, ..., 0.72117567, 1.28791994,\n",
              "        1.0507035 ],\n",
              "       ...,\n",
              "       [0.80983583, 0.66889562, 1.35025843, ..., 1.29697422, 0.97833751,\n",
              "        0.32553621],\n",
              "       [1.0514513 , 1.45819103, 1.46280698, ..., 1.37761926, 0.21742566,\n",
              "        0.6231897 ],\n",
              "       [0.97623705, 1.60718618, 0.79353096, ..., 0.42997723, 0.79103978,\n",
              "        0.63922755]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z ##이해하기기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8FRRqfEcXZ0"
      },
      "source": [
        "### 벡터 확장장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "ulCzIURocXZ0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X = np.random.random((32, 10))\n",
        "y = np.random.random((10,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWZ7LC1JrDEc"
      },
      "outputs": [],
      "source": [
        "x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "2wT0ar6rcXZ1"
      },
      "outputs": [],
      "source": [
        "y = np.expand_dims(y, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_E9CtgsrAB-",
        "outputId": "9b2870b3-5f33-4567-9f15-36721bd80be7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.87081039, 0.01854175, 0.01411217, 0.23733693, 0.73466781,\n",
              "        0.27843977, 0.44210644, 0.1856916 , 0.4128355 , 0.96624393]])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "DxkpfejZcXZ1"
      },
      "outputs": [],
      "source": [
        "Y = np.concatenate([y] * 32, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8tW4RtOrFfh"
      },
      "outputs": [],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "RD_DlHnwcXZ2"
      },
      "outputs": [],
      "source": [
        "def naive_add_matrix_and_vector(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzah2y8CrVcS",
        "outputId": "f334e8a4-5c71-4a99-c4ea-5be12d04d495"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 3, 32, 10)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "FysixZ6icXZ3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = np.random.random((64, 3, 32, 10))\n",
        "y = np.random.random((32, 10))\n",
        "z = np.maximum(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoDRmoivrxkR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axolcHaDcXZ3"
      },
      "source": [
        "### tensor 곱곱"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "3WU6TjWJcXZ4"
      },
      "outputs": [],
      "source": [
        "x = np.random.random((32,))\n",
        "y = np.random.random((32,))\n",
        "z = np.dot(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "CopM4EhAcXZ4"
      },
      "outputs": [],
      "source": [
        "def naive_vector_dot(x, y):\n",
        "    assert len(x.shape) == 1\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[0] == y.shape[0]\n",
        "    z = 0.\n",
        "    for i in range(x.shape[0]):\n",
        "        z += x[i] * y[i]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "vfAmc2kLcXZ5"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_vector_dot(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            z[i] += x[i, j] * y[j]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "QInlL3TacXZ6"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_vector_dot(x, y):\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        z[i] = naive_vector_dot(x[i, :], y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "gg_Ws5-GcXZ6"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_dot(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 2\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros((x.shape[0], y.shape[1]))\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(y.shape[1]):\n",
        "            row_x = x[i, :]\n",
        "            column_y = y[:, j]\n",
        "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFrVfqfcu7n8"
      },
      "outputs": [],
      "source": [
        "### x.shape[0]과 y.shape[1]의 숫자가 일치해야 한다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erM_6i1auE8H"
      },
      "outputs": [],
      "source": [
        "x = np.random.random((32,40))\n",
        "y = np.random.random((40,30))\n",
        "\n",
        "k = naive_matrix_dot(x, y)\n",
        "k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P7D2WBZcXZ6"
      },
      "source": [
        "### Tensor 재형성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2XfWB6pcXZ7"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDLD0Ft2cXZ7"
      },
      "outputs": [],
      "source": [
        "x = np.array([[0., 1.],\n",
        "             [2., 3.],\n",
        "             [4., 5.]])\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgLG-TdKcXZ7"
      },
      "outputs": [],
      "source": [
        "x = x.reshape((6, 1))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTQlf4STcXZ8"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((300, 20))\n",
        "x = np.transpose(x)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "v = tf.Variable(initial_value=tf.random.normal(shape(3,1)))\n",
        "print(v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "v.assign(tf.ones(3,1)) #3,1 전체를 1로 변경\n",
        "v[0,0].assign(3.) #0,0의 텐서를 3으로 변경\n",
        "v.assign_add(tf.ones(3,1)) # #3,1 전체에 1씩 더해줌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.square #제곱\n",
        "tf.sqrt #제곱근\n",
        "tf.matmul #곱"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lXVHcRecXZ-"
      },
      "source": [
        "#### The gradient tape in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xewxeVT8cXZ-",
        "outputId": "40104ac8-ad04-4cd1-c429-ec18b536a988"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "x = tf.Variable(0.)\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x + 3\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)\n",
        "grad_of_y_wrt_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inpit_const = tf.constant(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(input_const)\n",
        "    result = tf.square(input_const)\n",
        "gradient = tape.gradient(result, input_const)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G36uAMPScXZ_",
        "outputId": "983d6faf-a1b3-4ecd-975e-ebd4e83cdc32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[2., 2.],\n",
              "       [2., 2.]], dtype=float32)>"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.Variable(tf.random.uniform((2, 2)))\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x + 3\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)\n",
        "grad_of_y_wrt_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U3bj7U3cXZ_",
        "outputId": "085eeb11-f2b2-498d-a00c-cec6b2eebecf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              " array([[0.52146184, 0.52146184],\n",
              "        [0.8696399 , 0.8696399 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W = tf.Variable(tf.random.uniform((2, 2)))\n",
        "b = tf.Variable(tf.zeros((2,)))\n",
        "x = tf.random.uniform((2, 2))\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.matmul(x, W) + b\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])\n",
        "grad_of_y_wrt_W_and_b ##X는 랜덤 변수여서 값이 달라짐. [W,b]는 미분변수임."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4ml0MfXveym",
        "outputId": "65ba67c2-f42d-4c9a-a087-06080392a090"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
              "array([[0.8894763 , 0.5832864 ],\n",
              "       [0.28207886, 0.46914053]], dtype=float32)>"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kktqOyZsyC-p",
        "outputId": "11b55e9c-efb6-4716-b92a-991976bd50a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[  6.9140224,  53.865982 ],\n",
              "        [ 27.65609  , 215.46393  ],\n",
              "        [ 20.742067 , 161.59795  ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 6.9140224, 53.865982 ], dtype=float32)>]"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.constant(np.array([1.,4.,3.]).reshape(1,3), dtype=tf.float32)\n",
        "W = tf.Variable(tf.random.uniform((3,2)), dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros((2,)), dtype=tf.float32)\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.matmul(x, W) + b\n",
        "    k = tf.pow(y, 3)\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(k, [W, b])\n",
        "grad_of_y_wrt_W_and_b\n",
        "\n",
        "x = tf.constant(np.array([1.,4.,3.]).reshape(1,3), dtype=tf.float32)\n",
        "W = tf.Variable(tf.random.uniform((3,2)), dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros((2,)), dtype=tf.float32)\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.matmul(x, W) + b\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])\n",
        "grad_of_y_wrt_W_and_b\n",
        "\n",
        "x = tf.Variable(2.)\n",
        "y = tf.Variable(1.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    k = (x*x)*y + x*y + 3*y\n",
        "\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(k ,[x,y])\n",
        "grad_of_y_wrt_W_and_b"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oFYh5Ocl4L-A"
      },
      "source": [
        "# 미분 과제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC0Ggouy2BaB",
        "outputId": "f1eb323b-aef0-4431-8bff-50daf674be9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[1., 1.],\n",
              "        [4., 4.],\n",
              "        [3., 3.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>]"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.constant(np.array([1.,4.,3.]).reshape(1,3), dtype=tf.float32)\n",
        "W = tf.Variable(tf.random.uniform((3,2)), dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros((2,)), dtype=tf.float32)\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.matmul(x, W) + b\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])\n",
        "grad_of_y_wrt_W_and_b\n",
        "\n",
        "x = tf.Variable(2.)\n",
        "y = tf.Variable(1.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    k = (x*x)*y + x*y + 3*y\n",
        "\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(k ,[x,y])\n",
        "grad_of_y_wrt_W_and_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U19RMQwr2J5D",
        "outputId": "6f261c75-4cad-47dc-e776-d7008c1f7705"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=5.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=9.0>]"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.Variable(2.)\n",
        "y = tf.Variable(1.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    k = (x*x)*y + x*y + 3*y\n",
        "\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(k ,[x,y])\n",
        "grad_of_y_wrt_W_and_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "tzAhKibpzVT8"
      },
      "outputs": [],
      "source": [
        "x = np.random.random((64, 20))\n",
        "y = np.random.random((20,))\n",
        "\n",
        "def naive_add_matrix_and_vector(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAsOfVXezcMT",
        "outputId": "0a8a3fc5-ddfe-4e23-d58f-66fd810df492"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20,)"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.random.random((64, 20))\n",
        "y = np.random.random((20,))\n",
        "\n",
        "naive_add_matrix_and_vector(x, y)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEnux1_YcXaA"
      },
      "source": [
        "## Looking back at our first example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "NglTsXfFcXaA"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "y78dmQnscXaA"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "HDPbrDUocXaA"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dH-mmaBzcXaB"
      },
      "outputs": [],
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgyt9NgbcXaB"
      },
      "source": [
        "### Reimplementing our first example from scratch in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiBDm-xNcXaB"
      },
      "source": [
        "#### A simple Dense class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IytQV8txcXaC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.activation = activation\n",
        "\n",
        "        w_shape = (input_size, output_size)\n",
        "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        self.W = tf.Variable(w_initial_value)\n",
        "\n",
        "        b_shape = (output_size,)\n",
        "        b_initial_value = tf.zeros(b_shape)\n",
        "        self.b = tf.Variable(b_initial_value)\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IKzUrA5cXaC"
      },
      "source": [
        "#### A simple Sequential class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR4HLoa0cXaC"
      },
      "outputs": [],
      "source": [
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "           x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "       weights = []\n",
        "       for layer in self.layers:\n",
        "           weights += layer.weights\n",
        "       return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6reTrMLQcXaD"
      },
      "outputs": [],
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "])\n",
        "assert len(model.weights) == 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fWIKROicXaD"
      },
      "source": [
        "#### A batch generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5Rf61sfcXaD"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17imI7o8cXaE"
      },
      "source": [
        "### Running one training step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0KJUn9OcXaE"
      },
      "outputs": [],
      "source": [
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images_batch)\n",
        "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            labels_batch, predictions)\n",
        "        average_loss = tf.reduce_mean(per_sample_losses)\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc2qOso0cXaE"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    for g, w in zip(gradients, weights):\n",
        "        w.assign_sub(g * learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL-9FGS4cXaF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYiJ9xWXcXaF"
      },
      "source": [
        "### The full training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9aCeyhhcXaF"
      },
      "outputs": [],
      "source": [
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print(f\"Epoch {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okd8_xP6cXaG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek1LF8oCcXaG"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxpFC3ZBcXaG"
      },
      "outputs": [],
      "source": [
        "predictions = model(test_images)\n",
        "predictions = predictions.numpy()\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == test_labels\n",
        "print(f\"accuracy: {matches.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAX-S1-CcXaG"
      },
      "source": [
        "## 2장 끝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF0qvdFZ4OCb"
      },
      "source": [
        "# 3장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2E9LPN14UVW"
      },
      "source": [
        "#미분 함수수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvlotWqy4S0X"
      },
      "outputs": [],
      "source": [
        "x = tf.constant(np.array([1.,4.,3.]).reshape(1,3), dtype=tf.float32)\n",
        "W = tf.Variable(tf.random.uniform((3,2)), dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros((2,)), dtype=tf.float32)\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.matmul(x, W) + b\n",
        "    k = tf.pow(y, 3)\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(k, [W, b])\n",
        "grad_of_y_wrt_W_and_b\n",
        "\n",
        "x = tf.constant(np.array([1.,4.,3.]).reshape(1,3), dtype=tf.float32)\n",
        "W = tf.Variable(tf.random.uniform((3,2)), dtype=tf.float32)\n",
        "b = tf.Variable(tf.zeros((2,)), dtype=tf.float32)\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.matmul(x, W) + b\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])\n",
        "grad_of_y_wrt_W_and_b\n",
        "\n",
        "x = tf.Variable(2.)\n",
        "y = tf.Variable(1.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    k = (x*x)*y + x*y + 3*y\n",
        "\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(k ,[x,y])\n",
        "grad_of_y_wrt_W_and_b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxLMvARo45YR"
      },
      "source": [
        "#2D 클래스 생성성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fOgbnCN43xk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "num_samples_per_class = 200\n",
        "negative_samples = np.random.multivariate_normal(\n",
        "    mean=[2, 3],\n",
        "    cov=[[1, 0.2],[0.2, 1]],\n",
        "    size=num_samples_per_class)\n",
        "positive_samples = np.random.multivariate_normal(\n",
        "    mean=[3, 1],\n",
        "    cov=[[1, 0.5],[0.5, 1]],\n",
        "    size=num_samples_per_class)\n",
        "\n",
        "\n",
        "##cov (k, asdf), (asdf, p) asdf숫자는 반드시 일치해야 함!\n",
        "inputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\n",
        "\n",
        "targets = np.vstack((np.zeros((num_samples_per_class, 1), dtype=\"float32\"),\n",
        "                     np.ones((num_samples_per_class, 1), dtype=\"float32\")))\n",
        "#vstack numpy 합치는 펑션\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:,0])\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 직선 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_dim = 2\n",
        "output_dim = 1\n",
        "W = tf.Variable(initial_value=tf.random.unoform(shape=(input_dim, output_dim)))\n",
        "b = tf.Variable(initial_value=tf.zeros(shape=(output_dim,)))\n",
        "\n",
        "def model (inputs):\n",
        "    return tf.matual (inputs,W) + b\n",
        "\n",
        "def square_loss(targets, predictions):\n",
        "    per_sample_losses = tf.square(targets - predictions)\n",
        "    return tf.reduce_mean(per_sample_losses)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### training step function\n",
        "\n",
        "learning_rate = 0.1\n",
        "def training_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        perdictions = model(inputs)\n",
        "        loss = square_loss(predictions, targets)\n",
        "    grad_loss_wrt_W, grad_loss_wrt_b= tape.gradient(loss, [W, b])\n",
        "    W.assign_sub(grad_loss_wrt_W * learing_rate)\n",
        "    b.assign_sub(grad_loss_wrt_b * learing_rate) \n",
        "    return loss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 적용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.linspace(-1, 4, 100)\n",
        "y = -W[0] / W[1] * x + (0.5 - b) / W[1]\n",
        "plt.plot(x, y, \"-r\")\n",
        "plt.scatter(inputs[:, 0], inputs[: , 1], c=predictions[:, 0] > 0.5)\n",
        "\n",
        "#w1*x + w2*y +b = o.5 --> y = -w1/w2*x + (.5-b)/w2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#5 정확도 에러 그래프 그리기"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#모델 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "train_images_with_noise_channels = np.concatenate(\n",
        "    [train_images, np.random.random((len(train_images), 784))], axis=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#제로, 노이즈 데이터셋 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "train_images_origin = train_images\n",
        "\n",
        "train_images_with_zeros_channels = np.concatenate(\n",
        "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(): #함수 설정\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ]) #컴파일 정리 하기\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "history_noise = model.fit(\n",
        "    train_images_with_noise_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)\n",
        "\n",
        "model = get_model()\n",
        "history_zeros = model.fit(\n",
        "    train_images_with_zeros_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)\n",
        "\n",
        "model = get_model() #일반 데이터 데이터 셋\n",
        "history_origin = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##### ++++ 훈련을 랜덤으로 섞고 훈련 이미지와 랜덤 레이블로 모델 핏.\n",
        "#둘 관계가 없기 때문에 training loss가 떨어짐.\n",
        "#test acc가 90%, val acc가 10%로 될 수 있다.\n",
        "random_train_labels = train_labels[:]\n",
        "np.random.shuffle(random_train_labels)\n",
        "\n",
        "modle.fit(train_images, random_train_labels,\n",
        "         epochs= 100,\n",
        "         batch_size=128,\n",
        "         validation_split=0.2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#그래프 그리기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt #위에 설정한 데이터에 기반한 그래프\n",
        "val_acc_origin  = history_origin.history[\"val_accuracy\"]\n",
        "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
        "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
        "epochs = range(1, 11) # 반복 수\n",
        "plt.plot(epochs, val_acc_origin, \"g-\",\n",
        "         label=\"Validation accuracy with origin chnnels\")\n",
        "plt.plot(epochs, val_acc_noise, \"b-\",\n",
        "         label=\"Validation accuracy with noise channels\")\n",
        "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
        "         label=\"Validation accuracy with zeros channels\")\n",
        "plt.title(\"Effect of noise channels on validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#데이터 쪼갠 후 트레이닝 세트 실시 후 테스트 셋으로 검"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "random_train_labels_x = train_images[:50000]\n",
        "random_train_labels_y = train_labels[:50000]\n",
        "\n",
        "random_test_labels_x = train_images[50000:]\n",
        "random_test_labels_y = train_labels[50000:]\n",
        "\n",
        "np.random.shuffle(random_train_labels_x)\n",
        "np.random.shuffle(random_train_labels_y)\n",
        "np.random.shuffle(random_test_labels_x)\n",
        "np.random.shuffle(random_test_labels_y)\n",
        "\n",
        "history = model.fit(random_train_labels_x,\n",
        "                    random_train_labels_y,\n",
        "                    epochs=20,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(random_test_labels_x, random_test_labels_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#돌린거 찾기(정확도, 에러, 타당 정확도, 타당 에러)\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#트레이닝 셋, 검정 셋 정확도 그래프\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "acc_values = history_dict[\"accuracy\"]\n",
        "val_acc_values = history_dict[\"val_accuracy\"]\n",
        "epochs = range(1, len(acc_values) + 1)\n",
        "plt.plot(epochs, acc_values, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc_values, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation acc\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#학습률, Learning rate, 높으면 에러 높다, 적으면 과적\n",
        "optimizer=keras.optimizers.RMSprop(0.1),\n",
        "\n",
        "#adding weight regularization\n",
        "#layers.Dense(16,\n",
        "kernel_regularizer=regularizers.12(0.002),\n",
        "#activation=\"relu,\")\n",
        "\n",
        "\n",
        "#regularizer을 걸면 overfitting은 안되지만 좋은 성과를 보여주지 않음."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#large layers layer(노드)수 증가\n",
        "#more hidden layer 층 자체를 증가."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#데이터 벡터화.\n",
        "\n",
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "train_data = vectorize_sequences(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#그래프 그리기\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "val_loss_origin  = history_origin.history[\"val_loss\"]\n",
        "val_loss_larger = history_noise.history[\"val_loss\"]\n",
        "val_loss_smaller = history_zeros.history[\"val_loss\"]\n",
        "epochs = range(1, 11)\n",
        "plt.plot(epochs, val_loss_origin, \"g-\",\n",
        "         label=\"Validation loss with origin\")\n",
        "plt.plot(epochs, val_loss_larger, \"b-\",\n",
        "         label=\"Validation loss with larger\")\n",
        "plt.plot(epochs, val_loss_smaller, \"r-\",\n",
        "         label=\"Validation loss with smaller\")\n",
        "plt.title(\"Effect of size on validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Val_loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#드랍아웃 설정. 만일 드랍아웃을 제거하고 싶다면 그냥 평션만 제거\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5), #얘만 제거하면 원본 데이터 셋.\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history_dropout = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#데이터 인덱스 화, 무조건 3빼기.\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict(\n",
        "    [(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = \" \".join(\n",
        "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])\n",
        "\n",
        "#0,1,2 = padding, start of sequence and unknown\n",
        "#영화, 출력층은 시그몰드 함수. (-무한, 무한) y는 0~1(0이면 네거티브, 1이면 파지티브 리)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#predict 함수. # 뉴스 페이퍼\n",
        "model.predict(x_test)\n",
        "#위에 벡터화 함수 참고\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "#데이터 라벨 #라벨, 차원만큼의 0벡터 생성 -> 데이터가 있는 곳만 1로변경 46개의 셀 중 의미 있는 셀만 1로 되고 나머지는 전부 0.\n",
        "\n",
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results\n",
        "y_train = to_one_hot(train_labels)\n",
        "y_test = to_one_hot(test_labels)\n",
        "\n",
        "#범주화 시키기\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(train_labels)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "#뉴스 결론\n",
        "model = keras.Sequrntial([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "# 층이 46개니까\n",
        "\n",
        "##시그몰드 1덴스, 소프트맥스 2덴스\n",
        "\n",
        "#보스턴 하우스 데이터 셋\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
        "\n",
        "#normalizing the data -> 처리가 빠르다.\n",
        "mean = train_Data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "test_data -= mean\n",
        "test_data /= std\n",
        "\n",
        "#model definition\n",
        "#regression model에서 출력층 액티베이션을 쓸 필요가 없다\n",
        "#leayer.Dense(1)이 끝이다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#폴드 셔플화\n",
        "num_validation_samples = 10000\n",
        "np.random.shuffle(data)\n",
        "validation_data = data[:num_validation_samples]\n",
        "training_data = data(num_validation_samples:)\n",
        "#밑에는 똑다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#K폴드\n",
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "for i in range(k):\n",
        "    print(f\"Processing fold #{i}\")\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples] #(i~(i+1)번째까지 데이터)\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples] \n",
        "    partial_train_data = np.concatenate(         #그 외 나머지 :주의해서 볼것.\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    model = build_model()\n",
        "    model.fit(partial_train_data, partial_train_targets,\n",
        "              epochs=num_epochs, batch_size=16, verbose=0)\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    all_scores.append(val_mae)  #### validation data 모델 평\n",
        "\n",
        "\n",
        "#히스토리 생성. 위와 비교해서 볼것. 각 epoch별로 기록을 저장.\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size=16, verbose=0)\n",
        "    mae_history = history.history[\"val_mae\"]\n",
        "    all_mae_histories.append(mae_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#K 폴드, 폴드 별 mae 평균.\n",
        "average_mae_history = [\n",
        "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
        "\n",
        "#그래프가 너무 매끄러우면 보통 epoc가 많아서 그렇다.\n",
        "#폴드 mae 평균 함수 그래\n",
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation MAE\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# training the final model\n",
        "\n",
        "model = build_model()\n",
        "model.fit(train_data, train_tragets,\n",
        "         epochs=130, batch_size=16, verbose=0)\n",
        "test_mse_score, test_mae_score = modle.evaluate(test_data, test_targets)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#층이 많으면 acc가 상승함.그러나 overfitting 조심\n",
        "#노드가 많으면 overfitting이 빠르게 상승함."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chapter02_mathematical-building-blocks.i",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
